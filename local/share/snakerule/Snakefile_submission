include: "../snakemake/conf_submission.sk"

# ==========================================================================
#                             EGAsubmitter
# ==========================================================================
# This file is part of EGAsubmitter.
#
# EGAsubmitter is Free Software: you can redistribute it and/or modify it
# under the terms found in the LICENSE.rst file distributed
# together with this file.
#
# EGAsubmitter is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.
#
# ==========================================================================
# Author: Marco Viviani <marco.viviani@ircc.it>
# ==========================================================================
#                           Snakefile_submission
# This is the main snakemake pipeline of EGAsubmitter; here there are all
# the processes that create the needed files, link them together where
# needed and submit to the user's EGA account
# ==========================================================================

### --------Preparation part-------- ###
rule all:
    input: DONE+"/dataset.done"
    output: DONE+"/AllSubmissions.done"
    shell:
        """
            echo "All done:
            Please, check on the web page
            https://ega-archive.org/submitter-portal/#/login
            if everything is fine, you shall proceed with the validation"
            touch {output}
        """
### Converts all the yaml files given by the user: the user must place all the files in the yaml/ folder, after filling them out
rule allYaml:
    input: expand(USER_METADATA+"/json/{what}.json", what=FILES)
    output: touch(DONE+"/yamlConversion.done")
    shell: 'echo "All .yaml files have been converted to .json"'
rule yamlConversion:
    input: yaml=ancient(USER_METADATA+"/yaml/{what}.yaml") ###itera sui campi dello yaml, se è un numero, apri il txt corrispondente e vedere che sia nel range: se trovi numero ma non c'è il file corrispondete, passa
    params: enums=ENUMS
    output: json=USER_METADATA+"/json/{what}.json" 
    run:
        import os, yaml, json, glob, sys
        import pandas as pd

        enums = params.enums
        txt = glob.glob(os.path.join(enums,"*.txt"), recursive=True)
        with open(input.yaml) as y:
            file = yaml.safe_load(y)
            for key, value in file.items():
                if isinstance(value, list):
                    print(value)
                    if value:
                        val, = value
                        if isinstance(val, dict):
                            pass
                        else:
                            print(val)
                            if val.isdigit():
                                if list(filter(lambda x:key in x, txt)):
                                    f = pd.read_csv(os.path.join(enums,key+".txt"), sep='\t', header=0)
                                    if int(val) not in f['tag']:
                                        print("It seems that the tag you used for {} is not present in\n {} 'tag' column.\nPlease check it again.".format(key, list(filter(lambda x:key in x, txt))))
                                        sys.exit()
                else:
                    if value.isdigit():
                        if list(filter(lambda x:key in x, txt)):
                            f = pd.read_csv(os.path.join(enums,key+".txt"), sep='\t', header=0)
                            if int(value) not in f['tag']:
                                print("It seems that the tag you used for {} is not present in\n {} 'tag' column.\nPlease check it again.".format(key, list(filter(lambda x:key in x, txt))))
                                sys.exit()
            with open(output.json, "w") as json_out:
                json.dump(file, json_out, indent=1)

### This will build the Runs file, one for each sample: it depends on the encryption phase
checkpoint buildRuns:
    input: doneYaml=ancient(DONE+"/yamlConversion.done"), encrypted=ancient(TRANSFER+"/logs/done/filesCrypted.done")
    output: csv=SAMPLES_PATH+"/SamplesInformation.csv", done=DONE+"/buildRuns.done", samples=SAMPLES_PATH+"/Allfiles_list.txt", runs=RUNS_PATH+"/Allfiles_list.txt", allsamples=USER_METADATA+"/AllSamples_list.txt", desc=USER_METADATA+"/description", title=USER_METADATA+"/title"
    params: tool=SRC_DIR+"/buildRuns.py", path=DATASET, runType=FILETYPE, encryptedFiles=PROJECT_NAME, plate=TEMPLATE
    shell:
        """ 
            python3 {params.tool} -o {output.csv} -d {output.done} -p {params.path} -t {params.runType} -f {params.encryptedFiles} -j {params.plate}
        """ 

### This rule will build all the {samples}.json, starting from the .csv file filled by the user
rule buildSamples:
    input: getJson
    output: done=DONE+"/buildSamples.done"
    shell:
        """
            touch {output.done}
            echo "All samples.json have been built"
        """
rule samples:
    input: csv=ancient(SAMPLES_PATH+"/SamplesInformation.csv"), donebR=ancient(DONE+"/buildRuns.done")
    output: json=SAMPLES_PATH+"/{sample}.json", done=DONE+"/samples/json/{sample}.json.done"
    run:
        import json
        import csv
        primary_fields = ['alias', 'title', 'description', 'caseOrControlId', 'genderId',
        'organismPart', 'cellLine', 'region', 'phenotype', 'subjectId', 'anonymizedName', 'bioSampleId', 'sampleAge',
        'sampleDetail']
        with open(input.csv) as csv_file:
            reader = csv.DictReader(csv_file, skipinitialspace=True, delimiter=",")
            for row in reader:
                sample = row['alias']
                d = {k: v for k, v in row.items() if k in primary_fields}
                d['attributes'] = [{'tag': row['attributes.tag'], 'value': row['attributes.value']}]
                jsonString = json.dumps(d, indent=2)
                jsonFile = open(SAMPLES_PATH+"/"+sample+".json", "w")
                jsonFile.write(jsonString)
                jsonFile.close()
        open(output.done, 'a').close()

rule sub:
    input: json=ancient(DATA+"/SubmissionSubsetTemplate.json"), desc=USER_METADATA+"/description", title=USER_METADATA+"/title", doneSamples=ancient(DONE+"/buildSamples.done")
    output: submission=SUBMISSION_PATH+"/Submission.json", done=DONE+"/sub.done"
    params: path=DATASET
    run:
        import json
        
        with open(input.title) as t, open(input.desc) as d, open(input.json, 'r') as file:
            title = t.readline().strip()
            desc = d.readline().strip()
            df = json.load(file)
            df['title'] = title
            df['description'] = desc
        with open(output.submission, 'w') as sub:
            json.dump(df, sub, indent=2)
        open(output.done, 'a').close()
### --------Preparation part-------- ###


### --------Submission.json part-------- ###

### With this first submission we start the process and get the submission ID from EGA
rule submission:
    input: token=ancient("dataset/SessionToken"), json=ancient(SUBMISSION_PATH+"/Submission.json"), done=ancient(DONE+"/sub.done") ### This is the submission file with only title and description
    params: path=EGA_URL+"/submissions", idbckup=IDBCKUP
    output: id=SUBMISSION_PATH+"/SubmissionID", done=DONE+"/submission.done"
    log: SUB_LOGS+"/Submission_info.log",
    shell:
        """
            token=$(cat {input.token})
            curl -H "Content-type: application/json" -H "X-Token: $token" -X POST {params.path} -d @{input.json} > {log}
            jq -r '.response.result[0].id' {log} > {output.id}
            error=($(jq -r '.header.errorCode' {log}))
            if [ "$error" -ne 1 ]; then
                echo "Submission of Submission.json failed. The reason probably is:"
                jq -r '.header.userMessage' {log}
                exit 1
            fi
            touch {output.done}
            now=$(date +"%d_%m_%Y")
            cp {output.id} {output.id}_$now
            mv {output.id}_$now {params.idbckup}
            echo "Submission ID has been saved in {params.idbckup}"
            echo "Submission.json has been submitted"
        """

### STUDY ###
rule study:
    input: token=ancient("dataset/SessionToken"), json=ancient(USER_METADATA+"/json/Study.json"), id=ancient(SUBMISSION_PATH+"/SubmissionID"), done=ancient(DONE+"/submission.done")
    params: path=EGA_URL
    output: id=IDS+"/StudyID", done=DONE+"/study.done"
    log: SUB_LOGS+"/Study_submission.log"
    shell:
        """ 
            token=$(cat {input.token})
            path={params.path}/submissions/$(cat {input.id})/studies
            curl -H "Content-type: application/json" -H "X-Token: $token" -X POST $path -d @{input.json} > {log}
            jq -r '.response.result[0].id' {log} > {output.id}
            error=($(jq -r '.header.errorCode' {log}))
            if [ "$error" -ne 1 ]; then
                echo "Submission of Study.json failed. The reason probably is:"
                jq -r '.header.userMessage' {log}
                exit 1
            fi
            touch {output.done}
            echo "Study.json has been submitted"
        """
### --- ###

### SAMPLES ###
rule allSamples:
    input: getSample
    output: done=DONE+"/allSamples.done"
    shell:
        """
            touch {output.done}
            echo "All samples have been submitted"
        """
rule samplesSubmission:
    input: token=ancient("dataset/SessionToken"), json=ancient(SAMPLES_PATH+"/{sample}.json"), id=ancient(SUBMISSION_PATH+"/SubmissionID"), doneStudy=ancient(DONE+"/study.done")
    params: path=EGA_URL
    output: id=SAMPLES_PATH+"/IDs/{sample}_ID", done=DONE+"/samples/{sample}-sampleSubmission.done"
    log: SUB_LOGS+"/samples/{sample}.log"
    shell:
        """
            token=$(cat {input.token})
            path={params.path}/submissions/$(cat {input.id})/samples
            curl -H "Content-type: application/json" -H "X-Token: $token" -X POST $path -d @{input.json} > {log}
            jq -r '.response.result[0].id' {log} > {output.id}
            error=($(jq -r '.header.errorCode' {log}))
            if [ "$error" -ne 1 ]; then
                echo "Submission of {wildcards.sample}.json failed. The reason probably is:"
                jq -r '.header.userMessage' {log}
                exit 1
            fi
            touch {output.done}
            echo "{wildcards.sample}.json has been submitted"
        """
### --- ###

### EXPERIMENT ###
### Here the tool recover the Study ID (submitted before) and link it to the experiment
rule experimentAlias:
    input: json=ancient(USER_METADATA+"/json/Experiment.json"), idStudy=IDS+"/StudyID", doneStudy=ancient(DONE+"/study.done"), doneAllSamples=ancient(DONE+"/allSamples.done")
    output: after=SUBMISSION_PATH+"/Experiment.json", done=DONE+"/experimentAlias.done"
    run:
        import json
        with open(input.idStudy) as i:
            id = i.readline().strip()
        with open(input.json) as file:
            df = json.load(file)
            df['studyId'] = id
        with open(output.after, 'w') as json_file:
            json.dump(df, json_file, indent=2)
        open(output.done, 'a').close()
rule experimentSubmission:
    input: token=ancient("dataset/SessionToken"), json=SUBMISSION_PATH+"/Experiment.json", id=ancient(SUBMISSION_PATH+"/SubmissionID"), doneExpAl=ancient(DONE+"/experimentAlias.done")
    params: path=EGA_URL
    output: id=SUBMISSION_PATH+"/IDs/Experiment_ID", done=DONE+"/experimentSubmission.done"
    log: SUB_LOGS+"/experimentSubmission.log"
    shell:
        """ 
            token=$(cat {input.token})
            path={params.path}/submissions/$(cat {input.id})/experiments
            curl -H "Content-type: application/json" -H "X-Token: $token" -X POST $path -d @{input.json} > {log}
            jq -r '.response.result[0].id' {log} > {output.id}
            error=($(jq -r '.header.errorCode' {log}))
            if [ "$error" -ne 1 ]; then
                echo "Submission of Study.json failed. The reason probably is:"
                jq -r '.header.userMessage' {log}
                exit 1
            fi
            touch {output.done}
            echo "Experiment.json has been submitted"
        """
### --- ###

### RUNS ###
rule allRuns:
    input: getRun
    output: done=DONE+"/allRuns.done"
    shell:
        """
            touch {output.done}
            echo "All runs have been submitted"
        """
### Here the tool recover the Experiment ID and Samples IDs (submitted before) and link them to the Runs;
### Each Sample ID is linked to its specific Run file
rule runsAlias:
    input: json=ancient(RUNS_PATH+"/Run_{sample}.json"), idExp=SUBMISSION_PATH+"/IDs/Experiment_ID", idSample=SAMPLES_PATH+"/IDs/{sample}_ID", doneExp=ancient(DONE+"/experimentSubmission.done"), doneSample=ancient(DONE+"/allSamples.done")
    output: after=SUBMISSION_PATH+"/runs/Run_{sample}.json", done=DONE+"/runs/alias/runsAlias_{sample}.done"
    run:
        import json
        with open(input.idExp) as i, open(input.idSample) as s:
            id = i.readline().strip()
            sample = s.readline().strip()
        with open(input.json) as file:
            df = json.load(file)
            df['experimentId'] = id
            df['sampleId'] = sample
        with open(output.after, 'w') as json_file:
            json.dump(df, json_file, indent=2)
        open(output.done, 'a').close()
rule runsSubmission:
    input: token=ancient('dataset/SessionToken'), json=SUBMISSION_PATH+"/runs/Run_{sample}.json", id=ancient(SUBMISSION_PATH+"/SubmissionID"), donerunsAlias=ancient(DONE+"/runs/alias/runsAlias_{sample}.done")
    params: path=EGA_URL
    output: id=RUNS_PATH+"/IDs/Run_{sample}_ID", done=DONE+"/runs/{sample}-runSubmission.done"
    log: SUB_LOGS+"/runs/Run_{sample}.log"
    shell:
        """
            token=$(cat {input.token})
            path={params.path}/submissions/$(cat {input.id})/runs
            curl -H "Content-type: application/json" -H "X-Token: $token" -X POST $path -d @{input.json} > {log}
            jq -r '.response.result[0].id' {log} > {output.id}
            error=($(jq -r '.header.errorCode' {log}))
            if [ "$error" -ne 1 ]; then
                echo "Submission of Run_{wildcards.sample}.json failed. The reason probably is:"
                jq -r '.header.userMessage' {log}
                exit 1
            fi
            touch {output.done}
            echo "Run_{wildcards.sample}.json has been submitted"
        """
### --- ###

### DAC & Policy ###
rule dac:
    input: token=ancient('dataset/SessionToken'), json=ancient(USER_METADATA+"/json/DAC.json"), id=ancient(SUBMISSION_PATH+"/SubmissionID"), doneRuns=ancient(DONE+"/allRuns.done")
    params: path=EGA_URL
    output: id=IDS+"/DACID", done=DONE+"/dac.done"
    log: SUB_LOGS+"/DAC_submission.log"
    shell:
        """ 
            token=$(cat {input.token})
            path={params.path}/submissions/$(cat {input.id})/dacs
            curl -H "Content-type: application/json" -H "X-Token: $token" -X POST $path -d @{input.json} > {log}
            jq -r '.response.result[0].id' {log} > {output.id}
            error=($(jq -r '.header.errorCode' {log}))
            if [ "$error" -ne 1 ]; then
                echo "DAC upload failed. The reason probably is:"
                jq -r '.header.userMessage' {log}
                exit 1
            fi
            touch {output.done}
            echo "DAC.json has been submitted"
        """
### Here the tool recover the DAC ID (submitted before) and link it to the policy
rule policyAlias:
    input: json=ancient(USER_METADATA+"/json/Policy.json"), idDAC=IDS+"/DACID", doneDAC=ancient(DONE+"/dac.done")
    output: after=SUBMISSION_PATH+"/Policy.json", done=DONE+"/policyAlias.done"
    run:
        import json
        with open(input.idDAC) as i:
            id = i.readline().strip()
        with open(input.json) as file:
            df = json.load(file)
            df['dacId'] = id
        with open(output.after, 'w') as json_file:
            json.dump(df, json_file, indent=2)
        open(output.done, 'a').close()
rule policy:
    input: token=ancient('dataset/SessionToken'), json=SUBMISSION_PATH+"/Policy.json", done=ancient(DONE+"/policyAlias.done"), id=ancient(SUBMISSION_PATH+"/SubmissionID")
    params: path=EGA_URL
    output: id=IDS+"/PolicyID", done=DONE+"/policy.done"
    log: SUB_LOGS+"/Policy_submission.log"
    shell:
        """ 
            token=$(cat {input.token})
            path={params.path}/submissions/$(cat {input.id})/policies
            curl -H "Content-type: application/json" -H "X-Token: $token" -X POST $path -d @{input.json} > {log}
            jq -r '.response.result[0].id' {log} > {output.id}
            error=($(jq -r '.header.errorCode' {log}))
            if [ "$error" -ne 1 ]; then
                echo "Policy upload failed. The reason probably is:"
                jq -r '.header.userMessage' {log}
                exit 1
            fi
            touch {output.done}
            echo "Policy.json has been submitted"
        """
### --- ###

### DATASET ###
### Lastly, EGAsubmitter links everything in the Dataset.json
rule datasetAlias:
    input: json=ancient(USER_METADATA+"/json/Dataset.json"), idPolicy=IDS+"/PolicyID", done=ancient(DONE+"/policy.done")
    params: runIDpath=ancient(RUNS_PATH+"/IDs/")
    output: after=SUBMISSION_PATH+"/Dataset.json", done=DONE+"/datasetAlias.done"
    run:
        import json
        import os
        with open(input.json) as file:
            df = json.load(file)
        file = os.listdir(params.runIDpath)
        for filename in file:
            if filename.endswith("_ID"):
                with open(os.path.join(params.runIDpath, filename), 'r') as f:
                    runID = f.readline().strip()
                    df['runsReferences'].append(runID)
        with open(input.idPolicy) as i:
            id = i.readline().strip()
            df['policyId'] = id
        with open(output.after, 'w') as json_file:
            json.dump(df, json_file, indent=2)
        open(output.done, 'a').close()
rule dataset:
    input: token=ancient('dataset/SessionToken'), json=SUBMISSION_PATH+"/Dataset.json", id=ancient(SUBMISSION_PATH+"/SubmissionID"), done=ancient(DONE+"/datasetAlias.done")
    params: path=EGA_URL
    output: id=IDS+"/DatasetID", done=DONE+"/dataset.done"
    log: SUB_LOGS+"/Dataset_submission.log"
    shell:
        """ 
            token=$(cat {input.token})
            path={params.path}/submissions/$(cat {input.id})/datasets
            curl -H "Content-type: application/json" -H "X-Token: $token" -X POST $path -d @{input.json} > {log}
            jq -r '.response.result[0].id' {log} > {output.id}
            error=($(jq -r '.header.errorCode' {log}))
            if [ "$error" -ne 1 ]; then
                echo "Dataset upload failed. The reason probably is:"
                jq -r '.header.userMessage' {log}
                exit 1
            fi
            touch {output.done}
            echo "Dataset.json has been submitted"
        """
### --- ###
### --------Submission part-------- ###
